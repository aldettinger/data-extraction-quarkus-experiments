quarkus.langchain4j.chat-memory.memory-window.max-messages = 1

quarkus.langchain4j.ollama.base-url = http://localhost:11434
quarkus.langchain4j.ollama.timeout = 1m
quarkus.langchain4j.ollama.chat-model.model-id = codellama
quarkus.langchain4j.ollama.chat-model.format = json
quarkus.langchain4j.ollama.chat-model.temperature = 0
# Uncomment lines below to log Ollama client requests and responses
quarkus.langchain4j.ollama.log-requests=true
quarkus.langchain4j.ollama.log-responses=true

quarkus.native.resources.includes=texts/*.txt